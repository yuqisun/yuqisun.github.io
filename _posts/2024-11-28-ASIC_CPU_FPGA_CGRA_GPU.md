---
layout: post
title: "ASIC, CPU, FPGA, CGRA and GPU"
tagline: "ASIC, CPU, FPGA, CGRA, GPU"
---

FPGA vs. ASIC  
FPGA vs. CPU/GPU  
FPGA vs. CGRA  

### ASIC
Application-Specific Integrated Circuit.专用集成电路，为特定应用设计，针对任务或功能优化了，但是也是布线已经连接好了，不能变了。
比如比特币挖矿芯片，手机图像处理单元。

### CPU
处理通用任务。CPU 是 SIMD（single instruction, multiple data），单指令多数据，适用于向量化运算（这里说的是SIMD相对于原来CPU的进步，不是对比GPU）。
例如对于多元素数组，可同时对所有元素执行相同操作，从而提高效率。

### FPGA
是一堆逻辑门和开关，通过HDL描述电路功能，生成一个比特流文件，下载到FPGA就是用比特流文件控制用到的逻辑门和开关，建立逻辑单元间的连线路径。

### GPU
是SIMT（... threads）,同一时间执行多个线程。

CPU 是单靠一个线程多取数据，用满存储总线来提高效率。例如：  
内存带宽 131GB/s,内存delay 89ns，则89ns内可传输 131x89=11659字节（byte）。  

`ax+y` 将在89ns内传输16字节（double 8字节），内存带宽利用率 16/11659 = 0.14%，存储总线 99.86%空闲。  
要改善就一次多取数据， 11896/16=729次请求，但压力就给到线程这边，一个线程只能并发（轮片）不能并行，很难处理，比如2.9GHz core，89ns只能执行 89x2.9 = 258次，还得包括切换现场操作。

GPU就是直接729个线程并行计算（只是计算方面，调度的话多线程也没用）。

> Q: 那就是CPU能做的GPU都可以做？只是成本问题，GPU单core性能不如CPU，大概是CPU 1/2（也不低啊）。

GPU 靠线程多取胜，它拥有的线程数比实际需要多出五倍半，一部分线程等待数据，一部分等待被激活去计算，一部分正在计算。GPU内存要足够大，每个线程都有大量寄存器来存实时数据，免得搬运。

CGRA配置的是寄存器和互连路由控制计算单元和数据流。
#### 控制示例
1. 配置计算单元
假设一个PE中有 +, x, AND，PE的配置寄存器中可能有：  
a) 操作码字段：决定当前运算类型（如00 加法，01乘法，10 AND）  
b) 输入：操作数来自哪个输入端口  
c) 输出：结果传到哪个PE或存储单元

2. 配置互连网络
互连网络通过寄存器定义：
* 某个PE的输出如何连接到另一个PE的输入
* 路由优先级，例如是否需要通过全局总线还是点对点传输？

3. 任务调度
在执行多阶段任务时：  
a) 配置PE1 进行加法，输入来自数据流A和B  
b) 配置PE2 乘法，输入来自 PE1的输入和数据流 C  
c) 配置互连网络，将PE2的结果路由到存储单元

> Q: 那就是CGRA mxn 芯片生产出来，每个tile连线和Fu都是包含的，然后靠 HDL控制使用哪个？那还要 Layout干啥，生产出来的不就是 m和n不一样么？？

FPGA由大量小型可编程逻辑单元（查找表LUT）和互连网络组成；  
CGRA采用较大的计算单元（如算术逻辑单元ALU，乘加器）作为基本模块。

### 其他
- DRAM 是动态（电容实现，不刷新会出错，所以叫动态，断电丢失，就是平时说的内存）随机（相对于硬盘，不用以扇区为单位，而是可以任意位置）存取存储器；  
- SRAM 静态，不用刷新，cpu中用，断电也丢失；
- Flash 硬盘，不能随机读取。

